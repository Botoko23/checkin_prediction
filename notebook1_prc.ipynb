{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models built for check-in in next month prediction (imbalanced dataset handling method is used in this notebook)\n",
    "### Training dataset is up to end of Jun.2024 to see how models predict Jul.2024 check-in\n",
    "### The area under the precision-recall curve is around 5.5 which reflects the high recall, low precision nature for class 1  of previous notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### read in the necessary files\n",
    "import pandas as pd\n",
    "usr_segment = pd.read_csv(\"Jun_segmentation.csv\")\n",
    "features = pd.read_csv(\"features.csv\")\n",
    "openapp_recency = pd.read_csv(\"openapp_recency.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## merge dataset\n",
    "merged_1 = pd.merge(usr_segment, features, on='user_sn', how='inner')\n",
    "merged_2 = pd.merge(merged_1, openapp_recency, on='user_sn', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_sn                        int64\n",
       "segmentation                   int64\n",
       "hourly_ci_number               int64\n",
       "ovn_ci_number                  int64\n",
       "day_ci_number                  int64\n",
       "total_paid_from_user           int64\n",
       "usr_cancel_num_3_months        int64\n",
       "hotel_cancel_num_3_months      int64\n",
       "g2j_cancel_num_3_months        int64\n",
       "no_show_num_3_months           int64\n",
       "recency                        int64\n",
       "average_ci_time_gap          float64\n",
       "std_ci_time_gap              float64\n",
       "open_app_num_3_months        float64\n",
       "mileage_used_num             float64\n",
       "current_mileage_point        float64\n",
       "search_num_3_months          float64\n",
       "review_num_3_months          float64\n",
       "avg_mark                     float64\n",
       "time_since_join                int64\n",
       "user_province                 object\n",
       "ci_num                         int64\n",
       "openapp_recency                int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_2.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### feature explanation\n",
    "- segmentation: user segmentation by the month of train period\n",
    "\n",
    "- hourly_ci_number: user's number of hourly check-ins\n",
    "\n",
    "- ovn_ci_number: user's number of ovn check-ins \n",
    "\n",
    "- day_ci_number: user's number of day check-ins \n",
    "\n",
    "- total_paid_from_user: user's paid amount \n",
    "\n",
    "- usr_cancel_num_3_months: number of user cancels in the last 3 months in train period month\n",
    "\n",
    "- hotel_cancel_num_3_months: number of user cancels in the last 3 months in train period month\n",
    "\n",
    "- g2j_cancel_num_3_months: number of user cancels in the last 3 months  in train period month\n",
    "\n",
    "- no_show_num_3_months: number of noshow in the last 3 months in train period month\n",
    "\n",
    "- recency: the day difference between last check-in date before end of train period month and end of train period month\n",
    "\n",
    "- average_ci_time_gap: average day gap between check-ins\n",
    "\n",
    "- std_ci_time_gap: standard deviation of day gaps between check-ins\n",
    "\n",
    "- open_app_num_3_months: number of times user open app in the last 3 months in the train period month\n",
    "\n",
    "- mileage_used_num: number of times users used mileage points until end of train period month\n",
    "\n",
    "- current_mileage_point: mileage points of users by the end of train period month\n",
    "\n",
    "- search_num_3_months: number of times user search in the last 3 months in the train period month\n",
    "\n",
    "- review_num_3_months: number of times user give review in the last 3 months in the train period month\n",
    "\n",
    "- time_since_join: day gap between user's register date and end of train period month\n",
    "\n",
    "- user_province: Province of user\n",
    "\n",
    "- openapp_recency: the day difference between last open-app date before end of train period month and end of train period month\n",
    "\n",
    "- ci_num: number of user's check-ins in next month period (used to create target variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_sn                           0\n",
       "segmentation                      0\n",
       "hourly_ci_number                  0\n",
       "ovn_ci_number                     0\n",
       "day_ci_number                     0\n",
       "total_paid_from_user              0\n",
       "usr_cancel_num_3_months           0\n",
       "hotel_cancel_num_3_months         0\n",
       "g2j_cancel_num_3_months           0\n",
       "no_show_num_3_months              0\n",
       "recency                           0\n",
       "average_ci_time_gap               0\n",
       "std_ci_time_gap                   0\n",
       "open_app_num_3_months        117067\n",
       "mileage_used_num                239\n",
       "current_mileage_point         50134\n",
       "search_num_3_months          156746\n",
       "review_num_3_months          103449\n",
       "avg_mark                     103449\n",
       "time_since_join                   0\n",
       "user_province                     2\n",
       "ci_num                            0\n",
       "openapp_recency                   0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_2.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fill the null values with 0 for open_app_num_3_months, mileage_used_num, current_mileage_point\n",
    "## search_num_3_months, review_num_3_months, avg_mark\n",
    "merged_2[['open_app_num_3_months', 'mileage_used_num', 'current_mileage_point', \n",
    "          'review_num_3_months','search_num_3_months']] = merged_2[['open_app_num_3_months', 'mileage_used_num', 'current_mileage_point',\n",
    "                                                            'review_num_3_months','search_num_3_months',]].fillna(0).astype('int64')\n",
    "\n",
    "merged_2['avg_mark'] = merged_2['avg_mark'].fillna(0).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_sn                        int64\n",
       "segmentation                   int64\n",
       "hourly_ci_number               int64\n",
       "ovn_ci_number                  int64\n",
       "day_ci_number                  int64\n",
       "total_paid_from_user           int64\n",
       "usr_cancel_num_3_months        int64\n",
       "hotel_cancel_num_3_months      int64\n",
       "g2j_cancel_num_3_months        int64\n",
       "no_show_num_3_months           int64\n",
       "recency                        int64\n",
       "average_ci_time_gap          float64\n",
       "std_ci_time_gap              float64\n",
       "open_app_num_3_months          int64\n",
       "mileage_used_num               int64\n",
       "current_mileage_point          int64\n",
       "search_num_3_months            int64\n",
       "review_num_3_months            int64\n",
       "avg_mark                     float32\n",
       "time_since_join                int64\n",
       "user_province                 object\n",
       "ci_num                         int64\n",
       "openapp_recency                int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_2.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get rid of records with time_since_join or average_ci_time_gap < 0 and records with user_province as null\n",
    "merged_2 = merged_2[merged_2['time_since_join']>=0]\n",
    "merged_2 = merged_2[merged_2['average_ci_time_gap']>=0]\n",
    "merged_2 = merged_2[merged_2['user_province'].isnull()==False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(265085, 24)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segment_data = {\n",
    "    'segmentation': [1, 2, 3, 4, 5, 6, 7],\n",
    "    'segmentation_text': ['New', 'Existing', 'Retention', 'Win-back', 'Churn', 'Drop', 'Dormant']\n",
    "}\n",
    "\n",
    "segment_df = pd.DataFrame(segment_data)\n",
    "\n",
    "# add the segementaion test\n",
    "cleaned_df = pd.merge(merged_2, segment_df, on='segmentation', how='left')\n",
    "cleaned_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create target/dependent variable and train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ci_or_not\n",
       "0    242262\n",
       "1     22823\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_df['ci_or_not'] = cleaned_df['ci_num'].apply(lambda x: 1 if x > 0 else 0)\n",
    "cleaned_df['ci_or_not'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = cleaned_df.drop(columns=['user_sn','segmentation', 'ci_or_not', 'ci_num'],axis=1)\n",
    "y = cleaned_df['ci_or_not']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 19 numerical features : Index(['hourly_ci_number', 'ovn_ci_number', 'day_ci_number',\n",
      "       'total_paid_from_user', 'usr_cancel_num_3_months',\n",
      "       'hotel_cancel_num_3_months', 'g2j_cancel_num_3_months',\n",
      "       'no_show_num_3_months', 'recency', 'average_ci_time_gap',\n",
      "       'std_ci_time_gap', 'open_app_num_3_months', 'mileage_used_num',\n",
      "       'current_mileage_point', 'search_num_3_months', 'review_num_3_months',\n",
      "       'avg_mark', 'time_since_join', 'openapp_recency'],\n",
      "      dtype='object')\n",
      "\n",
      "We have 2 categorical features : Index(['user_province', 'segmentation_text'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "num_features = X.select_dtypes(exclude=\"object\").columns\n",
    "cat_features = X.select_dtypes(include=\"object\").columns\n",
    "\n",
    "print('We have {} numerical features : {}'.format(len(num_features), num_features))\n",
    "print('\\nWe have {} categorical features : {}'.format(len(cat_features), cat_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing, imbalanced data handling and train for Tree-based models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "oh_transformer = OneHotEncoder()\n",
    "numeric_transformer = StandardScaler()\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    [\n",
    "        (\"OneHotEncoder\", oh_transformer, cat_features),    \n",
    "        ('pass', 'passthrough', num_features)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold PRC AUC score: 0.5493\n",
      "Fold PRC AUC score: 0.5481\n",
      "Fold PRC AUC score: 0.5513\n",
      "PRC AUC score: 0.5496\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import make_scorer, precision_recall_curve, auc\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "skf = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "\n",
    "# Define a custom PRC AUC scoring function\n",
    "def prc_auc_score(y_true, y_scores):\n",
    "    precision, recall, _ = precision_recall_curve(y_true, y_scores)\n",
    "    return auc(recall, precision)\n",
    "\n",
    "# Create a custom scorer using make_scorer\n",
    "prc_auc_scorer = make_scorer(prc_auc_score, response_method='predict_proba')\n",
    "\n",
    "# smote technique\n",
    "smt = SMOTE()\n",
    "\n",
    "# Define the model and parameter grid\n",
    "rf = RandomForestClassifier(n_estimators=150, min_samples_split=2, min_samples_leaf=2, max_features='sqrt', max_depth=40, bootstrap=True)  # Fit the model\n",
    "\n",
    "\n",
    "# Store scores for each fold\n",
    "scores = []\n",
    "\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    # Split data\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "    # preprocessing\n",
    "    X_train_encoded = preprocessor.fit_transform(X_train)\n",
    "    X_test_encoded = preprocessor.transform(X_test)\n",
    "    \n",
    "    X_train_sm, y_train_sm = smt.fit_resample(X_train_encoded, y_train)\n",
    "\n",
    "    # Train the model\n",
    "    rf.fit(X_train_sm, y_train_sm)\n",
    "\n",
    "    # Predict on the test set\n",
    "    y_pred_proba = rf.predict_proba(X_test_encoded)[:, 1]\n",
    "\n",
    "    # Evaluate the model\n",
    "    precision, recall, _ = precision_recall_curve(y_test, y_pred_proba)\n",
    "    auc_score = auc(recall, precision)\n",
    "    scores.append(auc_score)\n",
    "    print(f\"Fold PRC AUC score: {auc_score:.4f}\")\n",
    "\n",
    "# Print the average accuracy across all folds\n",
    "print(f\"PRC AUC score: {np.mean(scores):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing, imbalanced data handling and train for non-tree-based models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "oh_transformer = OneHotEncoder()\n",
    "numeric_transformer = StandardScaler()\n",
    "\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    [\n",
    "        (\"OneHotEncoder\", oh_transformer, cat_features),\n",
    "         (\"StandardScaler\", numeric_transformer, num_features),        \n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold PRC AUC score: 0.5600\n",
      "Fold PRC AUC score: 0.5459\n",
      "Fold PRC AUC score: 0.5496\n",
      "Fold PRC AUC score: 0.5491\n",
      "Fold PRC AUC score: 0.5453\n",
      "PRC AUC score: 0.5500\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Input\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import precision_recall_curve, auc\n",
    "\n",
    "# Define the ANN model architecture\n",
    "def build_ann():\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(89,)))  # Specify the input shape using Input layer\n",
    "    model.add(Dense(64, activation='relu', kernel_initializer='glorot_uniform'))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(32, activation='relu', kernel_initializer='glorot_uniform'))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(1, activation='sigmoid', kernel_initializer='glorot_uniform'))\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Wrap the Keras model with KerasClassifier\n",
    "ann_model = KerasClassifier(model=build_ann, verbose=0)\n",
    "\n",
    "# smote technique\n",
    "smt = SMOTE()\n",
    "\n",
    "# Initialize StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=32)\n",
    "\n",
    "# Store scores for each fold\n",
    "scores = []\n",
    "\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    # Split data\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "    # preprocessing\n",
    "    X_train_encoded = preprocessor.fit_transform(X_train)\n",
    "    X_test_encoded = preprocessor.transform(X_test)\n",
    "    \n",
    "    X_train_sm, y_train_sm = smt.fit_resample(X_train_encoded, y_train)\n",
    "\n",
    "    # Train the model\n",
    "    ann_model.fit(X_train_sm, y_train_sm)\n",
    "\n",
    "    # Predict on the test set\n",
    "    y_pred_proba = ann_model.predict_proba(X_test_encoded)[:, 1]\n",
    "\n",
    "    # Evaluate the model\n",
    "    precision, recall, _ = precision_recall_curve(y_test, y_pred_proba)\n",
    "    auc_score = auc(recall, precision)\n",
    "    scores.append(auc_score)\n",
    "    print(f\"Fold PRC AUC score: {auc_score:.4f}\")\n",
    "\n",
    "# Print the average accuracy across all folds\n",
    "print(f\"PRC AUC score: {np.mean(scores):.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
